{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_17_Working with large data that doesn't fit your system memory - Semantic Segmentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##What is the best loss function for semantic segmentation?"
      ],
      "metadata": {
        "id": "W5tLCA0Zqwo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic segmentation models usually use a simple cross-categorical entropy loss function during training."
      ],
      "metadata": {
        "id": "sDt6jcPpqwu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##unet_loading_all_data.py"
      ],
      "metadata": {
        "id": "ssy5JwbVqw18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "U-Net example showing a use case where all data gets loaded to memory for training.\n",
        "Dataset: https://www.epfl.ch/labs/cvlab/data/data-em/\n",
        "\"\"\"\n",
        "\n",
        "from unet_model_with_functions_of_blocks import build_unet\n",
        "from keras.utils import normalize\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify, unpatchify\n",
        "import tifffile as tiff\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "image_directory = 'data/images/'\n",
        "mask_directory = 'data/masks/'\n",
        "\n",
        "\n",
        "SIZE = 256\n",
        "image_dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  \n",
        "mask_dataset = []  #Place holders to define add labels. We will add 0 to all parasitized images and 1 to uninfected.\n",
        "\n",
        "images = os.listdir(image_directory)\n",
        "for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
        "    if (image_name.split('.')[1] == 'tif'):\n",
        "        #print(image_directory+image_name)\n",
        "        image = cv2.imread(image_directory+image_name, 0)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        image_dataset.append(np.array(image))\n",
        "\n",
        "#Iterate through all images in Uninfected folder, resize to 64 x 64\n",
        "#Then save into the same numpy array 'dataset' but with label 1\n",
        "\n",
        "masks = os.listdir(mask_directory)\n",
        "for i, image_name in enumerate(masks):\n",
        "    if (image_name.split('.')[1] == 'tif'):\n",
        "        image = cv2.imread(mask_directory+image_name, 0)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        mask_dataset.append(np.array(image))\n",
        "\n",
        "image_dataset_uint8=np.array(image_dataset)\n",
        "mask_dataset_uint8=np.array(mask_dataset)\n",
        "\n",
        "print(\"Used memory to store the 8 bit int image dataset is: \", image_dataset_uint8.nbytes/(1024*1024), \"MB\")\n",
        "print(\"Used memory to store the 8 bit int mask dataset is: \", mask_dataset_uint8.nbytes/(1024*1024), \"MB\")\n",
        "\n",
        "#Normalize images\n",
        "image_dataset = np.expand_dims(normalize(np.array(image_dataset), axis=1),3)\n",
        "#D not normalize masks, just rescale to 0 to 1.\n",
        "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255.\n",
        "\n",
        "print(\"Used memory to store the float image dataset is: \", image_dataset.nbytes/(1024*1024), \"MB\")\n",
        "print(\"Used memory to store the float mask dataset is: \", mask_dataset.nbytes/(1024*1024), \"MB\")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.10, random_state = 0)\n",
        "\n",
        "#Sanity check, view few mages\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(X_train))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(X_train[image_number], (256, 256)), cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(y_train[image_number], (256, 256)), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "IMG_HEIGHT = image_dataset.shape[1]\n",
        "IMG_WIDTH  = image_dataset.shape[2]\n",
        "IMG_CHANNELS = image_dataset.shape[3]\n",
        "\n",
        "\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "model = build_unet(input_shape)\n",
        "model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size = 16, \n",
        "                    verbose=1, \n",
        "                    epochs=15, \n",
        "                    validation_data=(X_test, y_test), \n",
        "                    shuffle=False)\n",
        "\n",
        "#model.save('mitochondria_test.hdf5')\n",
        "\n",
        "\n",
        "\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "#acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "#val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#IOU\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_thresholded = y_pred > 0.5\n",
        "\n",
        "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
        "union = np.logical_or(y_test, y_pred_thresholded)\n",
        "iou_score = np.sum(intersection) / np.sum(union)\n",
        "print(\"IoU socre is: \", iou_score)\n",
        "\n",
        "#Predict on a few images\n",
        "#model = get_model()\n",
        "#model.load_weights('mitochondria_50_plus_100_epochs.hdf5') #Trained for 50 epochs and then additional 100\n",
        "#model.load_weights('mitochondria_gpu_tf1.4.hdf5')  #Trained for 50 epochs\n",
        "\n",
        "test_img_number = random.randint(0, len(X_test))\n",
        "test_img = X_test[test_img_number]\n",
        "ground_truth=y_test[test_img_number]\n",
        "test_img_norm=test_img[:,:,0][:,:,None]\n",
        "test_img_input=np.expand_dims(test_img_norm, 0)\n",
        "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.2).astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(prediction, cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ABYb5NQqw7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##split_folder_into_train_test_val.py"
      ],
      "metadata": {
        "id": "0Y376uV0qw-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Code for splitting folder into train, test, and val.\n",
        "Once the new folders are created rename them and arrange in the format below to be used\n",
        "for semantic segmentation using data generators. \n",
        "pip install split-folders\n",
        "\"\"\"\n",
        "import splitfolders  # or import split_folders\n",
        "\n",
        "input_folder = 'data/'\n",
        "\n",
        "# Split with a ratio.\n",
        "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
        "splitfolders.ratio(input_folder, output=\"data3\", seed=1337, ratio=(.8, .1, .1), group_prefix=None) # default values\n",
        "\n",
        "# Split val/test with a fixed number of items e.g. 100 for each set.\n",
        "# To only split into training and validation set, use a single number to `fixed`, i.e., `10`.\n",
        "#splitfolders.fixed(\"input_folder\", output=\"data2\", seed=1337, fixed=(100, 100), oversample=False, group_prefix=None) # default values\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "For semantic segmentation the folder structure needs to look like below\n",
        "if you want to use ImageDatagenerator.\n",
        "Data/\n",
        "    train_images/\n",
        "                train/\n",
        "                    img1, img2, img3, ......\n",
        "    \n",
        "    train_masks/\n",
        "                train/\n",
        "                    msk1, msk, msk3, ......\n",
        "                    \n",
        "    val_images/\n",
        "                val/\n",
        "                    img1, img2, img3, ......                \n",
        "    val_masks/\n",
        "                val/\n",
        "                    msk1, msk, msk3, ......\n",
        "      \n",
        "    test_images/\n",
        "                test/\n",
        "                    img1, img2, img3, ......    \n",
        "                    \n",
        "    test_masks/\n",
        "                test/\n",
        "                    msk1, msk, msk3, ......\n",
        "      \n",
        "                \n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7X3o17nYqxBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##unet_loading_data_from_drive.py"
      ],
      "metadata": {
        "id": "6l8jEYSkqxEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This code uses DataGen to directly load images from the drive in batches\n",
        "for training. This is best for datasets that do not fit in memory in its entirety. \n",
        "The code also uses DataGen for validation and testing. Checkout the tutorial (and code)\n",
        "to sort data into subdirectories in a way compatible for augmentation for semantic segmentation.\n",
        "For semantic segmentation the folder structure needs to look like below\n",
        "if you want to use ImageDatagenerator.\n",
        "Data/\n",
        "    train_images/\n",
        "                train/\n",
        "                    img1, img2, img3, ......\n",
        "    \n",
        "    train_masks/\n",
        "                train/\n",
        "                    msk1, msk, msk3, ......\n",
        "                    \n",
        "    val_images/\n",
        "                val/\n",
        "                    img1, img2, img3, ......                \n",
        "    val_masks/\n",
        "                val/\n",
        "                    msk1, msk, msk3, ......\n",
        "      \n",
        "    test_images/\n",
        "                test/\n",
        "                    img1, img2, img3, ......    \n",
        "                    \n",
        "    test_masks/\n",
        "                test/\n",
        "                    msk1, msk, msk3, ......\n",
        "Use split-folders library (pip install split-folders) to make this process of splitting\n",
        "files easy. \n",
        "import splitfolders  \n",
        "input_folder = 'data/'\n",
        "splitfolders.ratio(input_folder, output=\"data2\", seed=1337, ratio=(.8, .1, .1), group_prefix=None) \n",
        "Dataset: https://www.epfl.ch/labs/cvlab/data/data-em/\n",
        "\"\"\"\n",
        "\n",
        "from unet_model_with_functions_of_blocks import build_unet\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "#New generator with rotation and shear where interpolation that comes with rotation and shear are thresholded in masks. \n",
        "#This gives a binary mask rather than a mask with interpolated values. \n",
        "seed=24\n",
        "batch_size= 8\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_data_gen_args = dict(rescale = 1/255.,\n",
        "                         rotation_range=90,\n",
        "                      width_shift_range=0.3,\n",
        "                      height_shift_range=0.3,\n",
        "                      shear_range=0.5,\n",
        "                      zoom_range=0.3,\n",
        "                      horizontal_flip=True,\n",
        "                      vertical_flip=True,\n",
        "                      fill_mode='reflect')\n",
        "\n",
        "mask_data_gen_args = dict(rescale = 1/255.,  #Original pixel values are 0 and 255. So rescaling to 0 to 1\n",
        "                        rotation_range=90,\n",
        "                      width_shift_range=0.3,\n",
        "                      height_shift_range=0.3,\n",
        "                      shear_range=0.5,\n",
        "                      zoom_range=0.3,\n",
        "                      horizontal_flip=True,\n",
        "                      vertical_flip=True,\n",
        "                      fill_mode='reflect',\n",
        "                      preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)) #Binarize the output again. \n",
        "\n",
        "#If You need to resize images then add this to the flow_from_directory parameters \n",
        "#target_size=(150, 150), #Or whatever the size is for your network\n",
        "\n",
        "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
        "image_generator = image_data_generator.flow_from_directory(\"data2/train_images/\", \n",
        "                                                           seed=seed, \n",
        "                                                           batch_size=batch_size,\n",
        "                                                           class_mode=None)  #Very important to set this otherwise it returns multiple numpy arrays \n",
        "                                                                            #thinking class mode is binary.\n",
        "\n",
        "mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
        "mask_generator = mask_data_generator.flow_from_directory(\"data2/train_masks/\", \n",
        "                                                         seed=seed, \n",
        "                                                         batch_size=batch_size,\n",
        "                                                         color_mode = 'grayscale',   #Read masks in grayscale\n",
        "                                                         class_mode=None)\n",
        "\n",
        "\n",
        "valid_img_generator = image_data_generator.flow_from_directory(\"data2/val_images/\", \n",
        "                                                               seed=seed, \n",
        "                                                               batch_size=batch_size, \n",
        "                                                               class_mode=None) #Default batch size 32, if not specified here\n",
        "valid_mask_generator = mask_data_generator.flow_from_directory(\"data2/val_masks/\", \n",
        "                                                               seed=seed, \n",
        "                                                               batch_size=batch_size, \n",
        "                                                               color_mode = 'grayscale',   #Read masks in grayscale\n",
        "                                                               class_mode=None)  #Default batch size 32, if not specified here\n",
        "\n",
        "\n",
        "train_generator = zip(image_generator, mask_generator)\n",
        "val_generator = zip(valid_img_generator, valid_mask_generator)\n",
        "\n",
        "\n",
        "\n",
        "x = image_generator.next()\n",
        "y = mask_generator.next()\n",
        "for i in range(0,1):\n",
        "    image = x[i]\n",
        "    mask = y[i]\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image[:,:,0], cmap='gray')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask[:,:,0])\n",
        "    plt.show()\n",
        "\n",
        "#####################################################################\n",
        "#Define the model. Experiment with various loss functions and accuracy metrics\n",
        "# pip install focal-loss \n",
        "\n",
        "#######################################\n",
        "\n",
        "\n",
        "#Jaccard distance loss mimics IoU. \n",
        "from keras import backend as K\n",
        "def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
        "    \"\"\"\n",
        "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
        "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
        "    \n",
        "    The jaccard distance loss is usefull for unbalanced datasets. This has been\n",
        "    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n",
        "    gradient.\n",
        "    \n",
        "    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n",
        "    \n",
        "    @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n",
        "    @author: wassname\n",
        "    \"\"\"\n",
        "    intersection = K.sum(K.sum(K.abs(y_true * y_pred), axis=-1))\n",
        "    sum_ = K.sum(K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1))\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return (1 - jac) * smooth\n",
        "\n",
        "#Dice metric can be a great metric to track accuracy of semantic segmentation.\n",
        "def dice_metric(y_pred, y_true):\n",
        "    intersection = K.sum(K.sum(K.abs(y_true * y_pred), axis=-1))\n",
        "    union = K.sum(K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1))\n",
        "    # if y_pred.sum() == 0 and y_pred.sum() == 0:\n",
        "    #     return 1.0\n",
        "\n",
        "    return 2*intersection / union\n",
        "\n",
        "\n",
        "\n",
        "IMG_HEIGHT = x.shape[1]\n",
        "IMG_WIDTH  = x.shape[2]\n",
        "IMG_CHANNELS = x.shape[3]\n",
        "\n",
        "\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "model = build_unet(input_shape)\n",
        "\n",
        "#STANDARD BINARY CROSS ENTROPY AS LOSS AND ACCURACY AS METRIC\n",
        "#model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#JACCARD LOSS AND DICE METRIC \n",
        "# model.compile(optimizer=Adam(lr = 1e-3), loss=jaccard_distance_loss, \n",
        "#               metrics=[dice_metric])\n",
        "\n",
        "#FOCAL LOSS AND DICE METRIC\n",
        "#Focal loss helps focus more on tough to segment classes.\n",
        "from focal_loss import BinaryFocalLoss\n",
        "\n",
        "model.compile(optimizer=Adam(lr = 1e-3), loss=BinaryFocalLoss(gamma=2), \n",
        "              metrics=[dice_metric])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "num_train_imgs = len(os.listdir('data2/train_images/train/'))\n",
        "\n",
        "steps_per_epoch = num_train_imgs //batch_size\n",
        "\n",
        "\n",
        "history = model.fit_generator(train_generator, validation_data=val_generator, \n",
        "                    steps_per_epoch=steps_per_epoch, \n",
        "                    validation_steps=steps_per_epoch, epochs=50)\n",
        "\n",
        "\n",
        "\n",
        "model.save('mitochondria_load_from_disk.hdf5')\n",
        "\n",
        "\n",
        "\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['dice_metric']\n",
        "#acc = history.history['accuracy']\n",
        "val_acc = history.history['val_dice_metric']\n",
        "#val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training Dice')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Dice')\n",
        "plt.title('Training and validation Dice')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Dice')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "##############################################################\n",
        "#Test the model on images we held out for testing.\n",
        "#We can use the generator again for predictions. \n",
        "#Remember that this is not test time augmentation. This is only using augmentaton\n",
        "#to load images from the drive, perfomr augmentation and predict. \n",
        "# TTA means predicting on augmenting images and then combining predictions for better\n",
        "#accuracy. \n",
        "\n",
        "model = tf.keras.models.load_model(\"mitochondria_load_from_disk_focal_dice_50epochs.hdf5\", compile=False)\n",
        "\n",
        "test_img_generator = image_data_generator.flow_from_directory(\"data2/test_images/\", \n",
        "                                                              seed=seed, \n",
        "                                                              batch_size=32, \n",
        "                                                              class_mode=None) #Default batch size 32, if not specified here\n",
        "\n",
        "test_mask_generator = mask_data_generator.flow_from_directory(\"data2/test_masks/\", \n",
        "                                                              seed=seed, \n",
        "                                                              batch_size=32, \n",
        "                                                              color_mode = 'grayscale',   #Read masks in grayscale\n",
        "                                                              class_mode=None)  #Default batch size 32, if not specified here\n",
        "\n",
        "### Testing on a few test images\n",
        "\n",
        "a = test_img_generator.next()\n",
        "b = test_mask_generator.next()\n",
        "for i in range(0,5):\n",
        "    image = a[i]\n",
        "    mask = b[i]\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image[:,:,0], cmap='gray')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask[:,:,0])\n",
        "    plt.show()\n",
        "\n",
        "import random\n",
        "test_img_number = random.randint(0, a.shape[0]-1)\n",
        "test_img = a[test_img_number]\n",
        "ground_truth=b[test_img_number]\n",
        "#test_img_norm=test_img[:,:,0][:,:,None]\n",
        "test_img_input=np.expand_dims(test_img, 0)\n",
        "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.6).astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img, cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(prediction, cmap='gray')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#IoU for a single image\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "n_classes = 2\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(ground_truth[:,:,0], prediction)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())\n",
        "\n",
        "\n",
        "#Calculate IoU and average\n",
        " \n",
        "import pandas as pd\n",
        "\n",
        "IoU_values = []\n",
        "for img in range(0, a.shape[0]):\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,:,:,0] > 0.5).astype(np.uint8)\n",
        "    \n",
        "    IoU = MeanIoU(num_classes=n_classes)\n",
        "    IoU.update_state(ground_truth[:,:,0], prediction)\n",
        "    IoU = IoU.result().numpy()\n",
        "    IoU_values.append(IoU)\n",
        "\n",
        "    print(IoU)\n",
        "    \n",
        "\n",
        "\n",
        "df = pd.DataFrame(IoU_values, columns=[\"IoU\"])\n",
        "df = df[df.IoU != 1.0]    \n",
        "mean_IoU = df.mean().values\n",
        "print(\"Mean IoU is: \", mean_IoU)    "
      ],
      "metadata": {
        "id": "uNuIS-KjuDwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##unet_model_with_functions_of_blocks.py"
      ],
      "metadata": {
        "id": "FA5-KkPpuD8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Unet by dividing encoder and decoder into blocks\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Activation, MaxPool2D, Concatenate\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  #Not in the original network\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#Encoder block: Conv block followed by maxpooling\n",
        "\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "#Decoder block\n",
        "#skip features gets input from encoder for concatenation\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "#Build Unet using the blocks\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024) #Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)  #Binary (can be multiclass)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "AGbXeujpuD_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lXRNmWxTuECQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RfG9WqV7uEEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ysEDExMauEIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zLMw166gqxHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T1Yr76TaqxKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vFD056AgqxN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uhNIfox2qxQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fK3D7zCbqxTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DgwQ5BOPqxV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UR8sPTSLqxYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wbM2_qI1qxbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t72L9TfwqxfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tE7fnxcTqxhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nbW-hJHXqxlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eNAh5b4CqxoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l1xwijo7qxrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JfUWa5m3qx6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7oMS8ORIqx9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D0UrTx9zx6Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZcIuKauRx6Tw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}