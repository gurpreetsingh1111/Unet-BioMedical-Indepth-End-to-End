{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_14  Semantic segmentation using a small dataset for training (& U-Net).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Mitochondria U-net (Transfer learning using segmentation models) using small dataset \n",
        "(12 images and masks of 768x1024 each - further divided into 256x256 patches\n",
        " \n",
        " !pip install patchify\n",
        " !pip install segmentation-models==1.0.1\n",
        " \n",
        " \n",
        "Note: \n",
        "Importing segmentation models library may give you generic_utils error on TF2.x\n",
        "If you get an error about generic_utils...\n",
        "Option 1:\n",
        "change keras.utils.generic_utils.get_custom_objects().update(custom_objects) \n",
        "to keras.utils.get_custom_objects().update(custom_objects) \n",
        "in .../lib/python3.7/site-packages/efficientnet/__init__.py \n",
        "Use thhis code snippet to find out the location of site_packages directory\n",
        "under your current environment in anaconda. \n",
        "from distutils.sysconfig import get_python_lib\n",
        "print(get_python_lib())\n",
        "Option 2 (especially for Google Colab):\n",
        "Work with Tensorflow 1.x\n",
        "In google colab, add this as your fitst line.\n",
        "%tensorflow_version 1.x\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify\n",
        "import tifffile as tiff\n",
        "\n",
        "#All 165 images\n",
        "#large_image_stack = tiff.imread('full_dataset/images/mitochondria_train_01.tif')\n",
        "#large_mask_stack = tiff.imread('full_dataset/masks/mitochondria_train_masks_01.tif')\n",
        "\n",
        "#12 images only\n",
        "large_image_stack = tiff.imread('small_dataset_for_training/images/12_training_mito_images.tif')\n",
        "large_mask_stack = tiff.imread('small_dataset_for_training/masks/12_training_mito_masks.tif')\n",
        "\n",
        "print(large_image_stack.shape)\n",
        "\n",
        "all_img_patches = []\n",
        "for img in range(large_image_stack.shape[0]):\n",
        "    #print(img)     #just stop here to see all file names printed\n",
        "     \n",
        "    large_image = large_image_stack[img]\n",
        "    \n",
        "    patches_img = patchify(large_image, (256, 256), step=256)  #Step=256 for 256 patches means no overlap\n",
        "    \n",
        "\n",
        "    for i in range(patches_img.shape[0]):\n",
        "        for j in range(patches_img.shape[1]):\n",
        "            \n",
        "            single_patch_img = patches_img[i,j,:,:]\n",
        "            single_patch_img = (single_patch_img.astype('float32')) / 255.\n",
        "                  \n",
        "            all_img_patches.append(single_patch_img)\n",
        "\n",
        "images = np.array(all_img_patches)\n",
        "\n",
        "#Convert grey image to 3 channels by copying channel 3 times.\n",
        "#We do this as our unet model expects 3 channel input. \n",
        "images = np.stack((images,)*3, axis=-1)\n",
        "\n",
        "all_mask_patches = []\n",
        "for img in range(large_mask_stack.shape[0]):\n",
        "    #print(img)     #just stop here to see all file names printed\n",
        "     \n",
        "    large_mask = large_mask_stack[img]\n",
        "    \n",
        "    patches_mask = patchify(large_mask, (256, 256), step=256)  #Step=256 for 256 patches means no overlap\n",
        "    \n",
        "\n",
        "    for i in range(patches_mask.shape[0]):\n",
        "        for j in range(patches_mask.shape[1]):\n",
        "            \n",
        "            single_patch_mask = patches_mask[i,j,:,:]\n",
        "            single_patch_mask = single_patch_mask / 255.\n",
        "            \n",
        "            all_mask_patches.append(single_patch_mask)\n",
        "\n",
        "masks = np.array(all_mask_patches)\n",
        "masks = np.expand_dims(masks, -1)\n",
        "\n",
        "print(images.shape)\n",
        "print(masks.shape)\n",
        "print(\"Pixel values in the mask are: \", np.unique(masks))\n",
        "\n",
        "#Define the model\n",
        "import segmentation_models as sm\n",
        "\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input1 = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "# preprocess input\n",
        "images1=preprocess_input1(images)\n",
        "print(images1.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images1, masks, test_size = 0.25, random_state = 42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "#Sanity check, view few mages\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(X_train))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(X_train[image_number, :,:, 0], cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(y_train[image_number], (256, 256)), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#New generator with rotation and shear where interpolation that comes with rotation and shear are thresholded in masks. \n",
        "#This gives a binary mask rather than a mask with interpolated values. \n",
        "seed=24\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_data_gen_args = dict(rotation_range=90,\n",
        "                     width_shift_range=0.3,\n",
        "                     height_shift_range=0.3,\n",
        "                     shear_range=0.5,\n",
        "                     zoom_range=0.3,\n",
        "                     horizontal_flip=True,\n",
        "                     vertical_flip=True,\n",
        "                     fill_mode='reflect')\n",
        "\n",
        "mask_data_gen_args = dict(rotation_range=90,\n",
        "                     width_shift_range=0.3,\n",
        "                     height_shift_range=0.3,\n",
        "                     shear_range=0.5,\n",
        "                     zoom_range=0.3,\n",
        "                     horizontal_flip=True,\n",
        "                     vertical_flip=True,\n",
        "                     fill_mode='reflect',\n",
        "                     preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)) #Binarize the output again. \n",
        "\n",
        "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
        "image_data_generator.fit(X_train, augment=True, seed=seed)\n",
        "\n",
        "image_generator = image_data_generator.flow(X_train, seed=seed)\n",
        "valid_img_generator = image_data_generator.flow(X_test, seed=seed)\n",
        "\n",
        "mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
        "mask_data_generator.fit(y_train, augment=True, seed=seed)\n",
        "mask_generator = mask_data_generator.flow(y_train, seed=seed)\n",
        "valid_mask_generator = mask_data_generator.flow(y_test, seed=seed)\n",
        "\n",
        "def my_image_mask_generator(image_generator, mask_generator):\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img, mask) in train_generator:\n",
        "        yield (img, mask)\n",
        "\n",
        "my_generator = my_image_mask_generator(image_generator, mask_generator)\n",
        "\n",
        "validation_datagen = my_image_mask_generator(valid_img_generator, valid_mask_generator)\n",
        "\n",
        "x = image_generator.next()\n",
        "y = mask_generator.next()\n",
        "for i in range(0,1):\n",
        "    image = x[i]\n",
        "    mask = y[i]\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image[:,:,0], cmap='gray')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask[:,:,0])\n",
        "    plt.show()\n",
        "\n",
        "# define model\n",
        "model = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
        "model.compile('Adam', loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score])\n",
        "print(model.summary())\n",
        "\n",
        "#Fit the model\n",
        "#history = model.fit(my_generator, validation_data=validation_datagen, steps_per_epoch=len(X_train) // 16, validation_steps=len(X_train) // 16, epochs=100)\n",
        "history = model.fit(my_generator, validation_data=validation_datagen, steps_per_epoch=50, validation_steps=50, epochs=50)\n",
        "\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['iou_score']\n",
        "#acc = history.history['accuracy']\n",
        "val_acc = history.history['val_iou_score']\n",
        "#val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training IOU')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation IOU')\n",
        "plt.title('Training and validation IOU')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IOU')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#IOU\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_thresholded = y_pred > 0.5\n",
        "\n",
        "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
        "union = np.logical_or(y_test, y_pred_thresholded)\n",
        "iou_score = np.sum(intersection) / np.sum(union)\n",
        "print(\"IoU socre is: \", iou_score)\n",
        "\n",
        "test_img_number = random.randint(0, len(X_test)-1)\n",
        "test_img = X_test[test_img_number]\n",
        "test_img_input=np.expand_dims(test_img, 0)\n",
        "ground_truth=y_test[test_img_number]\n",
        "prediction = model.predict(test_img_input)\n",
        "prediction = prediction[0,:,:,0]\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(prediction, cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B4apgRBax6OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gWmDWO3RqwOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SjNqbb5PqwQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fSgicWdYqwTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MSX-MacxqwVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oVJaplnDqwZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-_0MatMTqwe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1FFu0UnCqwhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yprse0lkqwka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HznxXiFmqwmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W5tLCA0Zqwo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sDt6jcPpqwu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ssy5JwbVqw18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2ABYb5NQqw7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0Y376uV0qw-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7X3o17nYqxBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6l8jEYSkqxEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zLMw166gqxHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T1Yr76TaqxKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vFD056AgqxN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uhNIfox2qxQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fK3D7zCbqxTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DgwQ5BOPqxV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UR8sPTSLqxYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wbM2_qI1qxbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t72L9TfwqxfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tE7fnxcTqxhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nbW-hJHXqxlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eNAh5b4CqxoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l1xwijo7qxrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JfUWa5m3qx6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7oMS8ORIqx9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D0UrTx9zx6Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZcIuKauRx6Tw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}