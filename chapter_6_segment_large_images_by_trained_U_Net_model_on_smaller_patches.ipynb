{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter-6 segment large images by trained U-Net model on smaller patches.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##The right way to segment large images by applying a trained U-Net model on smaller patches"
      ],
      "metadata": {
        "id": "b6mVYpkIo5Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Applying trained model to large images. Not recommended, this code is intended for\n",
        "educational purposes only so we can see how we can get crappy results if we are not careful.\n",
        "\"\"\"\n",
        "from simple_unet_model import simple_unet_model   #Use normal unet model\n",
        "from keras.utils import normalize\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "#You can import model without defining input dimensions but not recommended. \n",
        "#Models work best when it segments objects of similar size as they got trained.\n",
        "\"\"\"def get_model():\n",
        "    return simple_unet_model(None, None, 1)\"\"\"\n",
        "\n",
        "#The right way to import model. In this case it got trained on 256x256 images\n",
        "def get_model():\n",
        "    return simple_unet_model(256, 256, 1)\n",
        "\n",
        "model = get_model()\n",
        "#######################################################################\n",
        "#Predict on a few images\n",
        "\n",
        "\"\"\"mitochondria_50_plus_100_epochs.hdf5 Model got trained on 256x256 images for 50 epochs\n",
        "But weights can be applied to larger images if we re-import model without \n",
        "defining input dimensions for the input layer.\n",
        "Beware that this is not recommended for semantic segmentation as we will soon find out...\"\"\"\n",
        "\n",
        "model.load_weights('mitochondria_50_plus_100_epochs.hdf5')  \n",
        "\n",
        "\n",
        "#Apply the trained model on large image\n",
        "large_image = cv2.imread('data/01-1.tif', 0)\n",
        "\n",
        "\"\"\"Resize - DO NOT do this mistake\n",
        "large_image = Image.fromarray(large_image)\n",
        "large_image = large_image.resize((256, 256))\n",
        "large_image = np.array(large_image)\n",
        "doing some preprocessing\"\"\"\n",
        "\n",
        "# initial array size=(768,1024)\n",
        "large_image_norm = np.expand_dims(normalize(np.array(large_image), axis=1),2)\n",
        "large_image_input=np.expand_dims(large_image_norm, 0) # expand the dimension by one  and normalize some values\n",
        "# now =array size=(768,1024,1)\n",
        "#Predict and threshold for values above 0.5 probability\n",
        "large_image_prediction = (model.predict(large_image_input)[0,:,:,0] > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(221)\n",
        "plt.title('External Image')\n",
        "plt.imshow(large_image, cmap='gray')\n",
        "plt.subplot(222)\n",
        "plt.title('Prediction of external Image')\n",
        "plt.imshow(large_image_prediction, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "#plt.imsave('data/results/output2.jpg', reconstructed_image, cmap='gray')"
      ],
      "metadata": {
        "id": "gQpS6u8Tqw7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###sem_segm_large_images_using_unet_with_custom_patch_inference"
      ],
      "metadata": {
        "id": "wY8ONoUoqw-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Applying trained model to large images by dividing them into smaller patches.\n",
        "This code uses 256x256 images/masks.\n",
        "\"\"\"\n",
        "#AIM= takes large image and patches into the small types of images\n",
        "from simple_unet_model import simple_unet_model \n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.utils import normalize\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "patch_size=256\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    return simple_unet_model(256, 256, 1)\n",
        "\n",
        "\n",
        "\n",
        "def prediction(model, image, patch_size):\n",
        "    segm_img = np.zeros(image.shape[:2])  #Array with zeros to be filled with segmented values\n",
        "    patch_num=1# how many patch number we have \n",
        "    for i in range(0, image.shape[0], 256):   #Steps of 256\n",
        "        for j in range(0, image.shape[1], 256):  #Steps of 256\n",
        "            #print(i, j)\n",
        "            single_patch = image[i:i+patch_size, j:j+patch_size]\n",
        "            single_patch_norm = np.expand_dims(normalize(np.array(single_patch), axis=1),2)\n",
        "            single_patch_shape = single_patch_norm.shape[:2]\n",
        "            single_patch_input = np.expand_dims(single_patch_norm, 0)\n",
        "            single_patch_prediction = (model.predict(single_patch_input)[0,:,:,0] > 0.5).astype(np.uint8)\n",
        "            segm_img[i:i+single_patch_shape[0], j:j+single_patch_shape[1]] += cv2.resize(single_patch_prediction, single_patch_shape[::-1])\n",
        "          \n",
        "            print(\"Finished processing patch number \", patch_num, \" at position \", i,j)\n",
        "            patch_num+=1\n",
        "    return segm_img\n",
        "\n",
        "##########\n",
        "#Load model and predict\n",
        "model = get_model()\n",
        "#model.load_weights('mitochondria_gpu_tf1.4.hdf5')\n",
        "model.load_weights('mitochondria_50_plus_100_epochs.hdf5')\n",
        "\n",
        "#Large image\n",
        "large_image = cv2.imread('data/01-1.tif', 0)\n",
        "segmented_image = prediction(model, large_image, patch_size)\n",
        "plt.hist(segmented_image.flatten())  #Threshold everything above 0\n",
        "\n",
        "plt.imsave('data/results/segm.jpg', segmented_image, cmap='gray')\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(221)\n",
        "plt.title('Large Image')\n",
        "plt.imshow(large_image, cmap='gray')\n",
        "plt.subplot(222)\n",
        "plt.title('Prediction of large Image')\n",
        "plt.imshow(segmented_image, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "##################################\n",
        "#Watershed to convert semantic to instance\n",
        "#########################\n",
        "from skimage import measure, color, io\n",
        "\n",
        "#Watershed\n",
        "img = cv2.imread('data/results/segm.jpg')  #Read as color (3 channels)\n",
        "img_grey = img[:,:,0]\n",
        "\n",
        "kernel = np.ones((3,3),np.uint8)\n",
        "opening = cv2.morphologyEx(img_grey,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
        "\n",
        "sure_bg = cv2.dilate(opening,kernel,iterations=10)\n",
        "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
        "\n",
        "ret2, sure_fg = cv2.threshold(dist_transform, 0.5*dist_transform.max(),255,0)\n",
        "\n",
        "sure_fg = np.uint8(sure_fg)\n",
        "unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "\n",
        "ret3, markers = cv2.connectedComponents(sure_fg)\n",
        "markers = markers+10\n",
        "\n",
        "markers[unknown==255] = 0\n",
        "\n",
        "markers = cv2.watershed(img, markers)\n",
        "img[markers == -1] = [0,255,255]  \n",
        "\n",
        "img2 = color.label2rgb(markers, bg_label=0)\n",
        "\n",
        "cv2.imshow('Overlay on original image', large_image)\n",
        "cv2.imshow('Colored Grains', img2)\n",
        "cv2.waitKey(0)\n",
        "props = measure.regionprops_table(markers, intensity_image=img_grey, \n",
        "                              properties=['label',\n",
        "                                          'area', 'equivalent_diameter',\n",
        "                                          'mean_intensity', 'solidity'])    \n",
        "import pandas as pd\n",
        "df = pd.DataFrame(props)\n",
        "df = df[df.mean_intensity > 100]  #Remove background or other regions that may be counted as objects\n",
        "   \n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "Pzhn0OI7r2FY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}