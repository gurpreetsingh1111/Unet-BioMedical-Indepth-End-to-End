{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_16_ Understanding U-Net architecture and building it from scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##unet_model_with_functions_of_blocks.py"
      ],
      "metadata": {
        "id": "MSX-MacxqwVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate\n",
        "\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  #Not in the original network\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#Encoder block: Conv block followed by maxpooling\n",
        "\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "#Decoder block\n",
        "#skip features gets input from encoder for concatenation\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "#Build Unet using the blocks\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024) #Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)  #Binary (can be multiclass)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "1FFu0UnCqwhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##unet_small_dataset_using_functional_blocks.py"
      ],
      "metadata": {
        "id": "Yprse0lkqwka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "U-Net \n",
        "Segmentation of mitochondria using only 12 images and about 150 labeled objects\n",
        "Dataset: https://www.epfl.ch/labs/cvlab/data/data-em/\n",
        "\"\"\"\n",
        "\n",
        "from unet_model_with_functions_of_blocks import build_unet\n",
        "from keras.utils import normalize\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify, unpatchify\n",
        "import tifffile as tiff\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "#12 images only\n",
        "large_image_stack = tiff.imread('small_dataset_for_training/images/12_training_mito_images.tif')\n",
        "large_mask_stack = tiff.imread('small_dataset_for_training/masks/12_training_mito_masks.tif')\n",
        "\n",
        "all_img_patches = []\n",
        "for img in range(large_image_stack.shape[0]):\n",
        "    #print(img)     #just stop here to see all file names printed\n",
        "     \n",
        "    large_image = large_image_stack[img]\n",
        "    \n",
        "    patches_img = patchify(large_image, (256, 256), step=256)  #Step=256 for 256 patches means no overlap\n",
        "    \n",
        "\n",
        "    for i in range(patches_img.shape[0]):\n",
        "        for j in range(patches_img.shape[1]):\n",
        "            \n",
        "            single_patch_img = patches_img[i,j,:,:]\n",
        "            single_patch_img = (single_patch_img.astype('float32')) / 255.\n",
        "            #scaler = MinMaxScaler()\n",
        "            #single_patch_img= scaler.fit_transform(single_patch_img)\n",
        "            \n",
        "            all_img_patches.append(single_patch_img)\n",
        "\n",
        "#This will split the image into small images of shape [3,3]\n",
        "images = np.array(all_img_patches)\n",
        "images = np.expand_dims(images, -1)\n",
        "\n",
        "all_mask_patches = []\n",
        "for img in range(large_mask_stack.shape[0]):\n",
        "    #print(img)     #just stop here to see all file names printed\n",
        "     \n",
        "    large_mask = large_mask_stack[img]\n",
        "    \n",
        "    patches_mask = patchify(large_mask, (256, 256), step=256)  #Step=256 for 256 patches means no overlap\n",
        "    \n",
        "\n",
        "    for i in range(patches_mask.shape[0]):\n",
        "        for j in range(patches_mask.shape[1]):\n",
        "            \n",
        "            single_patch_mask = patches_mask[i,j,:,:]\n",
        "            single_patch_mask = single_patch_mask / 255.\n",
        "            \n",
        "            all_mask_patches.append(single_patch_mask)\n",
        "\n",
        "#This will split the image into small images of shape [3,3]\n",
        "masks = np.array(all_mask_patches)\n",
        "masks = np.expand_dims(masks, -1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size = 0.25, random_state = 0)\n",
        "\n",
        "\n",
        "#Sanity check, view few mages\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(X_train))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(X_train[image_number], (256, 256)), cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(y_train[image_number], (256, 256)), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "IMG_HEIGHT = images.shape[1]\n",
        "IMG_WIDTH  = images.shape[2]\n",
        "IMG_CHANNELS = images.shape[3]\n",
        "\n",
        "\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "model = build_unet(input_shape)\n",
        "model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#New generator with rotation and shear where interpolation that comes with rotation and shear are thresholded in masks. \n",
        "#This gives a binary mask rather than a mask with interpolated values. \n",
        "seed=24\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_data_gen_args = dict(rotation_range=90,\n",
        "                     width_shift_range=0.3,\n",
        "                     height_shift_range=0.3,\n",
        "                     shear_range=0.5,\n",
        "                     zoom_range=0.3,\n",
        "                     horizontal_flip=True,\n",
        "                     vertical_flip=True,\n",
        "                     fill_mode='reflect')\n",
        "\n",
        "mask_data_gen_args = dict(rotation_range=90,\n",
        "                     width_shift_range=0.3,\n",
        "                     height_shift_range=0.3,\n",
        "                     shear_range=0.5,\n",
        "                     zoom_range=0.3,\n",
        "                     horizontal_flip=True,\n",
        "                     vertical_flip=True,\n",
        "                     fill_mode='reflect',\n",
        "                     preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)) #Binarize the output again. \n",
        "\n",
        "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
        "#image_data_generator.fit(X_train, augment=True, seed=seed)\n",
        "\n",
        "batch_size= 8\n",
        "\n",
        "image_generator = image_data_generator.flow(X_train, seed=seed, batch_size=batch_size)\n",
        "valid_img_generator = image_data_generator.flow(X_test, seed=seed, batch_size=batch_size) #Default batch size 32, if not specified here\n",
        "\n",
        "mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
        "#mask_data_generator.fit(y_train, augment=True, seed=seed)\n",
        "mask_generator = mask_data_generator.flow(y_train, seed=seed, batch_size=batch_size)\n",
        "valid_mask_generator = mask_data_generator.flow(y_test, seed=seed, batch_size=batch_size)  #Default batch size 32, if not specified here\n",
        "\n",
        "def my_image_mask_generator(image_generator, mask_generator):\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img, mask) in train_generator:\n",
        "        yield (img, mask)\n",
        "\n",
        "my_generator = my_image_mask_generator(image_generator, mask_generator)\n",
        "\n",
        "validation_datagen = my_image_mask_generator(valid_img_generator, valid_mask_generator)\n",
        "\n",
        "\n",
        "x = image_generator.next()\n",
        "y = mask_generator.next()\n",
        "for i in range(0,1):\n",
        "    image = x[i]\n",
        "    mask = y[i]\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image[:,:,0], cmap='gray')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask[:,:,0])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "steps_per_epoch = 3*(len(X_train))//batch_size\n",
        "\n",
        "\n",
        "history = model.fit_generator(my_generator, validation_data=validation_datagen, \n",
        "                    steps_per_epoch=steps_per_epoch, \n",
        "                    validation_steps=steps_per_epoch, epochs=25)\n",
        "\n",
        "\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "#acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "#val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#IOU\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_thresholded = y_pred > 0.5\n",
        "\n",
        "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
        "union = np.logical_or(y_test, y_pred_thresholded)\n",
        "iou_score = np.sum(intersection) / np.sum(union)\n",
        "print(\"IoU socre is: \", iou_score)\n",
        "\n",
        "#Predict on a few images\n",
        "#model = get_model()\n",
        "#model.load_weights('mitochondria_50_plus_100_epochs.hdf5') #Trained for 50 epochs and then additional 100\n",
        "#model.load_weights('mitochondria_gpu_tf1.4.hdf5')  #Trained for 50 epochs\n",
        "\n",
        "test_img_number = random.randint(0, len(X_test))\n",
        "test_img = X_test[test_img_number]\n",
        "ground_truth=y_test[test_img_number]\n",
        "test_img_norm=test_img[:,:,0][:,:,None]\n",
        "test_img_input=np.expand_dims(test_img_norm, 0)\n",
        "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.2).astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(prediction, cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HznxXiFmqwmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W5tLCA0Zqwo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sDt6jcPpqwu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ssy5JwbVqw18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2ABYb5NQqw7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0Y376uV0qw-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7X3o17nYqxBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6l8jEYSkqxEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zLMw166gqxHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T1Yr76TaqxKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vFD056AgqxN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uhNIfox2qxQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fK3D7zCbqxTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DgwQ5BOPqxV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UR8sPTSLqxYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wbM2_qI1qxbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t72L9TfwqxfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tE7fnxcTqxhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nbW-hJHXqxlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eNAh5b4CqxoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l1xwijo7qxrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JfUWa5m3qx6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7oMS8ORIqx9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D0UrTx9zx6Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZcIuKauRx6Tw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}