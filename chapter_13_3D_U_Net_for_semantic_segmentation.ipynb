{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_13_3D U-Net for semantic segmentation",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#This code uses 3D Unet to train a network on 3D subvolumes (64x64x64).\n",
        "#It also segments a large volume and outputs a multidimensional OMETIFF file\n",
        "#Custom dataset is used for this code but it should work on any dataset, including BRATS."
      ],
      "metadata": {
        "id": "enwgM7Rksy-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Latest Tensorflow (2.4) is giving error for some of the libraries we will be using, \n",
        "# especially segmentation models 3D. \n",
        "#Therefore, I am defining TF version 1.x. \n",
        "#If you have your own 3D unet model, you can try the latest TF version.\n",
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "id": "zgh--vs2ugSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install all dependencies for sgementation-models-3D library.\n",
        "#We will use this library to call 3D unet.\n",
        "#Alternative, you can define your own Unet, if you have skills!\n",
        "!pip install classification-models-3D\n",
        "!pip install efficientnet-3D\n",
        "!pip install segmentation-models-3D"
      ],
      "metadata": {
        "id": "o92CWSNeugyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use patchify to break large volumes into smaller for training \n",
        "#and also to put patches back together after prediction.\n",
        "!pip install patchify"
      ],
      "metadata": {
        "id": "FJtehuxPug0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "id": "xrom2HXyug29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make sure the GPU is available. \n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "qy_ddTqUug5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_3D as sm\n",
        "from skimage import io\n",
        "from patchify import patchify, unpatchify\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "_ENxvED4ug7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load input images and masks. \n",
        "#Here we load 256x256x256 pixel volume. We will break it into patches of 64x64x64 for training. \n",
        "image = io.imread('/content/drive/MyDrive/Colab Notebooks/data/sandstone_3d/training_data/train_images_256_256_256.tif')\n",
        "img_patches = patchify(image, (64, 64, 64), step=64)  #Step=64 for 64 patches means no overlap\n",
        "\n",
        "mask = io.imread('/content/drive/MyDrive/Colab Notebooks/data/sandstone_3d/training_data/train_masks_256_256_256.tif')\n",
        "mask_patches = patchify(mask, (64, 64, 64), step=64)  "
      ],
      "metadata": {
        "id": "9VF3VNj5ug9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_patches[1,2,3,:,:,32])\n",
        "#plt.imshow(mask_patches[1,2,3,:,:,32])"
      ],
      "metadata": {
        "id": "ndmfTJrDug_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = np.reshape(img_patches, (-1, img_patches.shape[3], img_patches.shape[4], img_patches.shape[5]))\n",
        "input_mask = np.reshape(mask_patches, (-1, mask_patches.shape[3], mask_patches.shape[4], mask_patches.shape[5]))\n",
        "\n",
        "print(input_img.shape)  # n_patches, x, y, z"
      ],
      "metadata": {
        "id": "DROV2RpZuhCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes=4\n",
        "#Convert grey image to 3 channels by copying channel 3 times.\n",
        "#We do this as our unet model expects 3 channel input. \n",
        "\n",
        "train_img = np.stack((input_img,)*3, axis=-1)\n",
        "train_mask = np.expand_dims(input_mask, axis=4)\n",
        "\n",
        "\n",
        "train_mask_cat = to_categorical(train_mask, num_classes=n_classes)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_img, train_mask_cat, test_size = 0.10, random_state = 0)"
      ],
      "metadata": {
        "id": "prrH8h-6uhEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function and coefficients to be used during training:\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    smoothing_factor = 1\n",
        "    flat_y_true = K.flatten(y_true)\n",
        "    flat_y_pred = K.flatten(y_pred)\n",
        "    return (2. * K.sum(flat_y_true * flat_y_pred) + smoothing_factor) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + smoothing_factor)\n",
        "\n",
        "def dice_coefficient_loss(y_true, y_pred):\n",
        "    return 1 - dice_coefficient(y_true, y_pred)"
      ],
      "metadata": {
        "id": "SrVEAQMyuhHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define parameters for our model.\n",
        "\n",
        "encoder_weights = 'imagenet'\n",
        "BACKBONE = 'vgg16'  #Try vgg16, efficientnetb7, inceptionv3, resnet50\n",
        "activation = 'softmax'\n",
        "patch_size = 64\n",
        "n_classes = 4\n",
        "channels=3\n",
        "\n",
        "LR = 0.0001\n",
        "optim = keras.optimizers.Adam(LR)\n",
        "\n",
        "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
        "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
        "dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.25, 0.25, 0.25, 0.25])) \n",
        "focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
        "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
        "\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]"
      ],
      "metadata": {
        "id": "ss_T5ymRu49e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n"
      ],
      "metadata": {
        "id": "3WM6upU6u5Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess input data - otherwise you end up with garbage resutls \n",
        "# and potentially model that does not converge.\n",
        "X_train_prep = preprocess_input(X_train)\n",
        "X_test_prep = preprocess_input(X_test)"
      ],
      "metadata": {
        "id": "l3ggD9tFu5Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the model. Here we use Unet but we can also use other model architectures from the library.\n",
        "model = sm.Unet(BACKBONE, classes=n_classes, \n",
        "                input_shape=(patch_size, patch_size, patch_size, channels), \n",
        "                encoder_weights=encoder_weights,\n",
        "                activation=activation)\n",
        "\n",
        "model.compile(optimizer = optim, loss=total_loss, metrics=metrics)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "u3t8pdlou5Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model\n",
        "history=model.fit(X_train_prep, \n",
        "          y_train,\n",
        "          batch_size=8, \n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test_prep, y_test))"
      ],
      "metadata": {
        "id": "A7HbxLEju5JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save model for future use\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/data/sandstone_3d/3D_model_vgg16_100epochs.h5')"
      ],
      "metadata": {
        "id": "q0hQgXVyu5M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "#plot the training and validation IoU and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['iou_score']\n",
        "val_acc = history.history['val_iou_score']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training IOU')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation IOU')\n",
        "plt.title('Training and validation IOU')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IOU')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vo2swtO3vHoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the pretrained model for testing and predictions. \n",
        "from keras.models import load_model\n",
        "my_model = load_model('/content/drive/MyDrive/Colab Notebooks/data/sandstone_3d/3D_model_vgg16_100epochs.h5', compile=False)\n",
        "#If you load a different model do not forget to preprocess accordingly. "
      ],
      "metadata": {
        "id": "04uhwyKMvHr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict on the test data\n",
        "y_pred=my_model.predict(X_test)\n",
        "y_pred_argmax=np.argmax(y_pred, axis=4)\n",
        "y_test_argmax = np.argmax(y_test, axis=4)"
      ],
      "metadata": {
        "id": "Z1alEeYhvHur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred_argmax.shape)\n",
        "print(y_test_argmax.shape)\n",
        "print(np.unique(y_pred_argmax))"
      ],
      "metadata": {
        "id": "CrQsUxixvHyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using built in keras function for IoU\n",
        "#Only works on TF > 2.0\n",
        "#from keras.metrics import MeanIoU\n",
        "#from keras.metrics import MeanIoU\n",
        "#n_classes = 4\n",
        "#IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "#IOU_keras.update_state(y_test_argmax, y_pred_argmax)\n",
        "#print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ],
      "metadata": {
        "id": "0vKyuWILvH5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test some random images\n",
        "import random\n",
        "test_img_number = random.randint(0, len(X_test))\n",
        "test_img = X_test[test_img_number]\n",
        "ground_truth=y_test[test_img_number]\n",
        "\n",
        "test_img_input=np.expand_dims(test_img, 0)\n",
        "test_img_input1 = preprocess_input(test_img_input)\n",
        "\n",
        "test_pred1 = my_model.predict(test_img_input1)\n",
        "test_prediction1 = np.argmax(test_pred1, axis=4)[0,:,:,:]\n",
        "print(test_prediction1.shape)"
      ],
      "metadata": {
        "id": "elIzdwhgvH8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_argmax = np.argmax(ground_truth, axis=3)\n",
        "print(test_img.shape)"
      ],
      "metadata": {
        "id": "PmwbnpnlvhEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot individual slices from test predictions for verification\n",
        "slice = 14\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[slice,:,:,0], cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth_argmax[slice,:,:])\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(test_prediction1[slice,:,:])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0k1LMpZYvms2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QD1ue-savmwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Break the large image (volume) into patches of same size as the training images (patches)\n",
        "large_image = io.imread('/content/drive/MyDrive/Colab Notebooks/data/sandstone_3d/all_images/448_images_512x512.tif')\n",
        "patches = patchify(large_image, (64, 64, 64), step=64)  #Step=256 for 256 patches means no overlap\n",
        "print(large_image.shape)\n",
        "print(patches.shape)"
      ],
      "metadata": {
        "id": "Te3ItRbXUNS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict each 3D patch   \n",
        "predicted_patches = []\n",
        "for i in range(patches.shape[0]):\n",
        "  for j in range(patches.shape[1]):\n",
        "    for k in range(patches.shape[2]):\n",
        "      #print(i,j,k)\n",
        "      single_patch = patches[i,j,k, :,:,:]\n",
        "      single_patch_3ch = np.stack((single_patch,)*3, axis=-1)\n",
        "      single_patch_3ch_input = preprocess_input(np.expand_dims(single_patch_3ch, axis=0))\n",
        "      single_patch_prediction = my_model.predict(single_patch_3ch_input)\n",
        "      single_patch_prediction_argmax = np.argmax(single_patch_prediction, axis=4)[0,:,:,:]\n",
        "      predicted_patches.append(single_patch_prediction_argmax)"
      ],
      "metadata": {
        "id": "l4R06sAwvmzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert list to numpy array\n",
        "predicted_patches = np.array(predicted_patches)\n",
        "print(predicted_patches.shape)"
      ],
      "metadata": {
        "id": "VFUhrHR_vm1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape to the shape we had after patchifying\n",
        "predicted_patches_reshaped = np.reshape(predicted_patches, \n",
        "                                        (patches.shape[0], patches.shape[1], patches.shape[2],\n",
        "                                         patches.shape[3], patches.shape[4], patches.shape[5]) )\n",
        "print(predicted_patches_reshaped.shape)"
      ],
      "metadata": {
        "id": "PE9bf-KBvm5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Repach individual patches into the orginal volume shape\n",
        "reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
        "print(reconstructed_image.shape)"
      ],
      "metadata": {
        "id": "irhOqY68v26F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reconstructed_image.dtype)"
      ],
      "metadata": {
        "id": "vRMSGJlvv29T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to uint8 so we can open image in most image viewing software packages\n",
        "reconstructed_image=reconstructed_image.astype(np.uint8)\n",
        "print(reconstructed_image.dtype)"
      ],
      "metadata": {
        "id": "zHEd6oyMv3BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now save it as segmented volume.\n",
        "from tifffile import imsave\n",
        "imsave('/content/drive/MyDrive/Colab Notebooks/data/sandstone_3d/all_images/segmented.tif', reconstructed_image)"
      ],
      "metadata": {
        "id": "WRdWT7JMv_XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(reconstructed_image))"
      ],
      "metadata": {
        "id": "yTEQYcpuv_a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seperate each channel/segment to be combined as multiple channels.\n",
        "num_segments=4\n",
        "segm0 = (reconstructed_image == 0)\n",
        "segm1 = (reconstructed_image == 1)\n",
        "segm2 = (reconstructed_image == 2)\n",
        "segm3 = (reconstructed_image == 3)\n",
        "\n",
        "final = np.empty((reconstructed_image.shape[0], reconstructed_image.shape[1], reconstructed_image.shape[2], num_segments))\n",
        "final[:,:,:,0] = segm0\n",
        "final[:,:,:,1] = segm1\n",
        "final[:,:,:,2] = segm2\n",
        "final[:,:,:,3] = segm3"
      ],
      "metadata": {
        "id": "i-35tgXrwISW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use APEER OMETIFF library to read and write multidimensional images\n",
        "!pip install apeer-ometiff-library"
      ],
      "metadata": {
        "id": "gvsAss8hwIUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from apeer_ometiff_library import io"
      ],
      "metadata": {
        "id": "uMor7HqgwIX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand image array to 5D of order (T, Z, C, X, Y)\n",
        "# This is the convention for OMETIFF format as written by APEER library\n",
        "final = np.expand_dims(final, axis=0)\n",
        "final=np.swapaxes(final, 2, 4)\n",
        "\n",
        "final = final.astype(np.int8)"
      ],
      "metadata": {
        "id": "Djkh1WfuwIaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the segmented volume is: T, Z, C, X, Y \", final.shape)\n",
        "print(final.dtype)"
      ],
      "metadata": {
        "id": "QXCDatVTwRv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write dataset as multi-dimensional OMETIFF *image*\n",
        "io.write_ometiff(\"/content/drive/MyDrive/Colab Notebooks/data/sandstone_3d/all_images/segmented_multi_channel.ome.tiff\", final)"
      ],
      "metadata": {
        "id": "cypsRL9nwRy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9zWqFV8wwR2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-FOnrNzowIc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "afM_b0niwIgW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}