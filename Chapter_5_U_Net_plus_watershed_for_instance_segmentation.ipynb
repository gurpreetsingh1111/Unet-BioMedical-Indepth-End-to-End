{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter-5 U-Net plus watershed for instance segmentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6mVYpkIo5Qf"
      },
      "outputs": [],
      "source": [
        "#Use normal unet model\n",
        "from simple_unet_model import simple_unet_model\n",
        "from keras.utils import normalize\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import measure, color, io\n",
        "\n",
        "\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH  = 256\n",
        "IMG_CHANNELS = 1\n",
        "\n",
        "def get_model():\n",
        "    return simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "#Load the model and corresponding weights\n",
        "model = get_model()\n",
        "#model.load_weights('mitochondria_50_plus_100_epochs.hdf5') #Trained for 50 epochs and then additional 100\n",
        "model.load_weights('mitochondria_gpu_tf1.4.hdf5') #Trained for 50 epochs you are trying to load the weights of the models\n",
        "\n",
        "#Load and process the test image - image that needs to be segmented. \n",
        "#test_img = cv2.imread('data/test_images/01-1_256.tif', 0)\n",
        "test_img = cv2.imread('data/test_images/img8.tif', 0)\n",
        "test_img_norm = np.expand_dims(normalize(np.array(test_img), axis=1),2)\n",
        "test_img_norm=test_img_norm[:,:,0][:,:,None]\n",
        "test_img_input=np.expand_dims(test_img_norm, 0)# (1,256,256,1) becoz i loaded 10 images\n",
        "\n",
        "#Predict and threshold for values above 0.5 probability\n",
        "segmented = (model.predict(test_img_input)[0,:,:,0] > 0.05).astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(221)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img, cmap='gray')\n",
        "plt.subplot(222)\n",
        "plt.title('Segmented Image')\n",
        "plt.imshow(segmented, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "plt.imsave('data/results/output.jpg', segmented, cmap='gray')\n",
        "\n",
        "########################################################\n",
        "#####Watershed\n",
        "\n",
        "img = cv2.imread('data/results/output.jpg')  #Read as color (3 channels)\n",
        "img_grey = img[:,:,0]\n",
        "\n",
        "## transform the unet result to binary image\n",
        "#Threshold image to binary using OTSU. ALl thresholded pixels will be set to 255\n",
        "ret1, thresh = cv2.threshold(img_grey, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "\n",
        "# Morphological operations to remove small noise - opening\n",
        "#To remove holes we can use closing\n",
        "kernel = np.ones((3,3),np.uint8)\n",
        "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
        "\n",
        "#from skimage.segmentation import clear_border\n",
        "#opening = clear_border(opening) #Remove edge touching grains. \n",
        "#Check the total regions found before and after applying this. \n",
        "\n",
        "#Now we know that the regions at the center of cells is for sure cells\n",
        "#The region far away is background.\n",
        "#We need to extract sure regions. For that we can use erode. \n",
        "#But we have cells touching, so erode alone will not work. \n",
        "#To separate touching objects, the best approach would be distance transform and then thresholding.\n",
        "\n",
        "# let us start by identifying sure background area\n",
        "# dilating pixes a few times increases cell boundary to background. \n",
        "# This way whatever is remaining for sure will be background. \n",
        "#The area in between sure background and foreground is our ambiguous area. \n",
        "#Watershed should find this area for us. \n",
        "sure_bg = cv2.dilate(opening,kernel,iterations=10)\n",
        "\n",
        "# Finding sure foreground area using distance transform and thresholding\n",
        "#intensities of the points inside the foreground regions are changed to \n",
        "#distance their respective distances from the closest 0 value (boundary).\n",
        "#https://www.tutorialspoint.com/opencv/opencv_distance_transformation.htm\n",
        "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
        "\n",
        "\n",
        "#Let us threshold the dist transform by starting at 1/2 its max value.\n",
        "ret2, sure_fg = cv2.threshold(dist_transform, 0.2*dist_transform.max(),255,0)\n",
        "\n",
        "#Later you may realize that 0.2*max value may be better. Also try other values. \n",
        "#High value like 0.7 will drop some small mitochondria. \n",
        "\n",
        "# Unknown ambiguous region is nothing but bkground - foreground\n",
        "sure_fg = np.uint8(sure_fg)\n",
        "unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "\n",
        "#Now we create a marker and label the regions inside. \n",
        "# For sure regions, both foreground and background will be labeled with positive numbers.\n",
        "# Unknown regions will be labeled 0. \n",
        "#For markers let us use ConnectedComponents. \n",
        "ret3, markers = cv2.connectedComponents(sure_fg)\n",
        "\n",
        "#One problem rightnow is that the entire background pixels is given value 0.\n",
        "#This means watershed considers this region as unknown.\n",
        "#So let us add 10 to all labels so that sure background is not 0, but 10\n",
        "markers = markers+10\n",
        "\n",
        "# Now, mark the region of unknown with zero\n",
        "markers[unknown==255] = 0\n",
        "#plt.imshow(markers, cmap='gray')   #Look at the 3 distinct regions.\n",
        "\n",
        "#Now we are ready for watershed filling. \n",
        "markers = cv2.watershed(img, markers)\n",
        "#plt.imshow(markers, cmap='gray')\n",
        "#The boundary region will be marked -1\n",
        "#https://docs.opencv.org/3.3.1/d7/d1b/group__imgproc__misc.html#ga3267243e4d3f95165d55a618c65ac6e1\n",
        "\n",
        "#Let us color boundaries in yellow. \n",
        "img[markers == -1] = [0,255,255]  \n",
        "\n",
        "img2 = color.label2rgb(markers, bg_label=0)\n",
        "\n",
        "cv2.imshow('Overlay on original image', img)\n",
        "cv2.imshow('Colored Grains', img2)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "#Now, time to extract properties of detected cells\n",
        "# regionprops function in skimage measure module calculates useful parameters for each object.\n",
        "\n",
        "\n",
        "props = measure.regionprops_table(markers, intensity_image=img_grey, \n",
        "                              properties=['label',\n",
        "                                          'area', 'equivalent_diameter',\n",
        "                                          'mean_intensity', 'solidity'])\n",
        "    \n",
        "import pandas as pd\n",
        "df = pd.DataFrame(props)\n",
        "df = df[df.mean_intensity > 100]  #Remove background or other regions that may be counted as objects\n",
        "\n",
        "print(df.head())\n"
      ]
    }
  ]
}