{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " chapter-3 U-Net for semantic segmentation of mitochondria datasets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#U-Net for semantic segmentation of mitochondria datasets"
      ],
      "metadata": {
        "id": "uF0MrhV47rPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##simple_unet_model.py"
      ],
      "metadata": {
        "id": "kjxUyQva22yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "\n",
        "################################################################\n",
        "def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
        "#Build the model\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
        "    s = inputs\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    \n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "     \n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "     \n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "     \n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "    \n",
        "    #Expansive path \n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "     \n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "     \n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "     \n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "     \n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "     \n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "rK9az0dt1jdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Results.py"
      ],
      "metadata": {
        "id": "EokvCHFr3EB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from simple_unet_model import simple_unet_model   #Use normal unet model\n",
        "from keras.utils import normalize\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image # Pillow is basically used  to resize the images \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "image_directory = 'data/generated_patches/images/'\n",
        "mask_directory = 'data/generated_patches/masks/'\n",
        "\n",
        "\n",
        "SIZE = 256\n",
        "# we have capture all images into this below list\n",
        "image_dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  \n",
        "mask_dataset = []  #Place holders to define add labels. We will add 0 to all parasitized images and 1 to uninfected.\n",
        "\n",
        "images = os.listdir(image_directory) # that have image01.tif into the list \n",
        "for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
        "    if (image_name.split('.')[1] == 'tif'):\n",
        "        #print(image_directory+image_name)\n",
        "        image = cv2.imread(image_directory+image_name, 0)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        image_dataset.append(np.array(image))\n",
        "\n",
        "#Iterate through all images in Uninfected folder, resize to 64 x 64\n",
        "#Then save into the same numpy array 'dataset' but with label 1\n",
        "\n",
        "masks = os.listdir(mask_directory)\n",
        "for i, image_name in enumerate(masks):\n",
        "    if (image_name.split('.')[1] == 'tif'):\n",
        "        image = cv2.imread(mask_directory+image_name, 0)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        mask_dataset.append(np.array(image))\n",
        "\n",
        "\n",
        "# now image_dataset and mask_dataset in the form of list so convert this into numpy array\n",
        "#Normalize images\n",
        "image_dataset = np.expand_dims(normalize(np.array(image_dataset), axis=1),3)\n",
        "#D not normalize masks, just rescale to 0 to 1.\n",
        "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255.\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.10, random_state = 0)\n",
        "\n",
        "#Sanity check, view few mages\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(X_train))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(X_train[image_number], (256, 256)), cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(y_train[image_number], (256, 256)), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "############################################################### (256x256x1)\n",
        "IMG_HEIGHT = image_dataset.shape[1]\n",
        "IMG_WIDTH  = image_dataset.shape[2]\n",
        "IMG_CHANNELS = image_dataset.shape[3]\n",
        "\n",
        "def get_model():\n",
        "    return simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "\n",
        "#If starting with pre-trained weights. \n",
        "#model.load_weights('mitochondria_gpu_tf1.4.hdf5')\n",
        "\n",
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size = 16, \n",
        "                    verbose=1, \n",
        "                    epochs=1, \n",
        "                    validation_data=(X_test, y_test), \n",
        "                    shuffle=False)\n",
        "\n",
        "model.save('mitochondria_test.hdf5')\n",
        "\n",
        "############################################################\n",
        "#Evaluate the model\n",
        "\n",
        "\n",
        "# evaluate model\n",
        "_, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
        "\n",
        "\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['acc']\n",
        "#acc = history.history['accuracy']\n",
        "val_acc = history.history['val_acc']\n",
        "#val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "##################################\n",
        "#IOU\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_thresholded = y_pred > 0.5 # Return T or F\n",
        " \n",
        "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
        "union = np.logical_or(y_test, y_pred_thresholded)\n",
        "iou_score = np.sum(intersection) / np.sum(union)\n",
        "print(\"IoU socre is: \", iou_score)\n",
        "\n",
        "#######################################################################\n",
        "#Predict on a few images\n",
        "model = get_model()\n",
        "model.load_weights('mitochondria_50_plus_100_epochs.hdf5') #Trained for 50 epochs and then additional 100\n",
        "#model.load_weights('mitochondria_gpu_tf1.4.hdf5')  #Trained for 50 epochs\n",
        "\n",
        "test_img_number = random.randint(0, len(X_test))\n",
        "test_img = X_test[test_img_number]\n",
        "ground_truth=y_test[test_img_number]\n",
        "test_img_norm=test_img[:,:,0][:,:,None]\n",
        "test_img_input=np.expand_dims(test_img_norm, 0)\n",
        "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.2).astype(np.uint8)\n",
        "\n",
        "test_img_other = cv2.imread('data/test_images/02-1_256.tif', 0) # this image is completely external \n",
        "#test_img_other = cv2.imread('data/test_images/img8.tif', 0)\n",
        "test_img_other_norm = np.expand_dims(normalize(np.array(test_img_other), axis=1),2)\n",
        "test_img_other_norm=test_img_other_norm[:,:,0][:,:,None]\n",
        "test_img_other_input=np.expand_dims(test_img_other_norm, 0)\n",
        "\n",
        "#Predict and threshold for values above 0.5 probability\n",
        "#Change the probability threshold to low value (e.g. 0.05) for watershed demo.\n",
        "prediction_other = (model.predict(test_img_other_input)[0,:,:,0] > 0.2).astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(prediction, cmap='gray')\n",
        "plt.subplot(234)\n",
        "plt.title('External Image')\n",
        "plt.imshow(test_img_other, cmap='gray')\n",
        "plt.subplot(235)\n",
        "plt.title('Prediction of external Image')\n",
        "plt.imshow(prediction_other, cmap='gray')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xCwJ-I8W1jf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-oNs8H241jh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "etTwseOT1jly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6do4QzBz4jvO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}